{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Load, process, visualise for the separate models\n",
    "DATA_PATH = '../../data/'\n",
    "OUT_PATH = '../figures/'\n",
    "SAMPLES_PATH = '../fitting_outputs/'\n",
    "RESULTS_PATH = '../results/'\n",
    "MAX_VAL = 133 \n",
    "MIN_VAL = 1  # or 1\n",
    "\n",
    "strat = 'wave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# load best models results\n",
    "df_best_models = pd.read_csv(RESULTS_PATH + 'best_models.csv')\n",
    "df_best_models = df_best_models.set_index(df_best_models.columns[0]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Epidemilogical distribution</th>\n",
       "      <th>icu_stay</th>\n",
       "      <th>hosp_stay</th>\n",
       "      <th>onset_icu</th>\n",
       "      <th>onset_hosp</th>\n",
       "      <th>onset_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gamma</th>\n",
       "      <td>1784.604885</td>\n",
       "      <td>13705.279845</td>\n",
       "      <td>3735.841745</td>\n",
       "      <td>6284.611918</td>\n",
       "      <td>460.013954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lognormal</th>\n",
       "      <td>160.504407</td>\n",
       "      <td>177.901618</td>\n",
       "      <td>928.318456</td>\n",
       "      <td>1156.085625</td>\n",
       "      <td>7.447201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weibull</th>\n",
       "      <td>3551.564872</td>\n",
       "      <td>19157.024686</td>\n",
       "      <td>5718.721788</td>\n",
       "      <td>15042.612995</td>\n",
       "      <td>2339.510146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exponential</th>\n",
       "      <td>7568.008197</td>\n",
       "      <td>23439.784061</td>\n",
       "      <td>15372.773116</td>\n",
       "      <td>47793.381182</td>\n",
       "      <td>8631.483925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gamma 3p</th>\n",
       "      <td>179759.907133</td>\n",
       "      <td>219187.681072</td>\n",
       "      <td>99057.537214</td>\n",
       "      <td>133422.419425</td>\n",
       "      <td>212046.575538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gen Lognormal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Epidemilogical distribution       icu_stay      hosp_stay     onset_icu  \\\n",
       "Gamma                          1784.604885   13705.279845   3735.841745   \n",
       "Lognormal                       160.504407     177.901618    928.318456   \n",
       "Weibull                        3551.564872   19157.024686   5718.721788   \n",
       "Exponential                    7568.008197   23439.784061  15372.773116   \n",
       "Gamma 3p                     179759.907133  219187.681072  99057.537214   \n",
       "Gen Lognormal                     0.000000       0.000000      0.000000   \n",
       "\n",
       "Epidemilogical distribution     onset_hosp    onset_death  \n",
       "Gamma                          6284.611918     460.013954  \n",
       "Lognormal                      1156.085625       7.447201  \n",
       "Weibull                       15042.612995    2339.510146  \n",
       "Exponential                   47793.381182    8631.483925  \n",
       "Gamma 3p                     133422.419425  212046.575538  \n",
       "Gen Lognormal                     0.000000       0.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# load the observed data\n",
    "drop_columns = ['start_date', 'end_date']\n",
    "\n",
    "df_icu_stay = pd.read_csv(DATA_PATH + 'icu_stay_bog.csv')\n",
    "df_icu_stay = df_icu_stay[(df_icu_stay['icu_stay'] > MIN_VAL)&(df_icu_stay['icu_stay'] <= MAX_VAL)]\n",
    "\n",
    "df_hosp_stay = pd.read_csv(DATA_PATH + 'hosp_stay_bog.csv')\n",
    "df_hosp_stay = df_hosp_stay[(df_hosp_stay['hosp_stay'] > MIN_VAL)&(df_hosp_stay['hosp_stay'].abs() <= MAX_VAL)]\n",
    "\n",
    "df_onset_icu = pd.read_csv(DATA_PATH + 'onset_icu_bog.csv')\n",
    "df_onset_icu = df_onset_icu[(df_onset_icu['onset_icu'] > MIN_VAL)&(df_onset_icu['onset_icu'] <= MAX_VAL)]\n",
    "\n",
    "df_onset_hosp = pd.read_csv(DATA_PATH + 'onset_hosp_bog.csv')\n",
    "df_onset_hosp = df_onset_hosp[(df_onset_hosp['onset_hosp'] > MIN_VAL)&(df_onset_hosp['onset_hosp'] <= MAX_VAL)]\n",
    "\n",
    "df_onset_death = pd.read_csv(DATA_PATH + 'onset_death_bog.csv')\n",
    "df_onset_death = df_onset_death[(df_onset_death['onset_death'] > MIN_VAL)&(df_onset_death['onset_death'] <= MAX_VAL)]\n",
    "\n",
    "all_dfs = [df_icu_stay, df_hosp_stay, df_onset_icu, df_onset_hosp, df_onset_death]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and preparation of data\n",
    "for df in all_dfs:\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "strat_ages = df_onset_icu['age_group'].unique()\n",
    "strat_sex = df_onset_icu['sex'].unique()\n",
    "strat_wave= df_onset_icu['wave'].unique()\n",
    "\n",
    "strat_sex.sort()\n",
    "strat_ages.sort()\n",
    "strat_wave.sort()\n",
    "\n",
    "strat_sex_map = dict(zip(strat_sex, list(range(1, len(strat_sex)+1))))\n",
    "strat_sex = list(range(1, len(strat_sex)+1))\n",
    "\n",
    "strat_ages_map = dict(zip(strat_ages, list(range(1, len(strat_ages)+1))))\n",
    "strat_ages = list(range(1, len(strat_ages)+1))\n",
    "\n",
    "strat_wave_map = dict(zip(strat_wave, list(range(1, len(strat_wave)+1))))\n",
    "strat_wave = list(range(1, len(strat_wave)+1))\n",
    "\n",
    "if strat=='wave':\n",
    "    strat_=strat_wave\n",
    "elif strat=='age':\n",
    "    strat_=strat_age\n",
    "elif strat=='sex':\n",
    "    strat_=strat_sex\n",
    "\n",
    "columns = []\n",
    "for df in all_dfs:\n",
    "    df.dropna(inplace=True) # remove the rows with nan values\n",
    "    col = str(df.columns[4])\n",
    "    columns.append(col)\n",
    "    df['age_group_id'] = df['age_group'].map(strat_ages_map)\n",
    "    df['sex_id'] = df['sex'].map(strat_sex_map)\n",
    "    df['wave_id'] = df['wave'].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q025(x):\n",
    "    return x.quantile(0.025)\n",
    "\n",
    "# 90th Percentile\n",
    "def q975(x):\n",
    "    return x.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icu_stay 28040 2.0 - 133.0\n",
      "hosp_stay 66652 2.0 - 133.0\n",
      "onset_icu 29248 2.0 - 133.0\n",
      "onset_hosp 77012 2.0 - 131.0\n",
      "onset_death 26469 2.0 - 133.0\n"
     ]
    }
   ],
   "source": [
    "stat = ['mean', q95, q05]\n",
    "##############################################################################\n",
    "# print n samples and range of data\n",
    "for df in all_dfs:\n",
    "    col = str(df.columns[4])\n",
    "    print(col, len(df[col].index), df[col].min(), '-', df[col].max())\n",
    "##############################################################################\n",
    "# load the samples (models fits for every epidemiological distribution)\n",
    "\n",
    "dist_posteriors  = {'icu_stay':{},\n",
    "                    'hosp_stay':{},\n",
    "                    'onset_icu':{},\n",
    "                    'onset_hosp':{},\n",
    "                    'onset_death':{}\n",
    "                   }\n",
    "\n",
    "for col in columns:\n",
    "    dist_posteriors[col].update({'Gamma': pd.read_csv(SAMPLES_PATH + col +'-samples-gamma_'+ strat + '.csv').agg(stat)})\n",
    "    dist_posteriors[col].update({'Lognormal': pd.read_csv(SAMPLES_PATH + col +'-samples-logn_'+ strat + '.csv').agg(stat)})\n",
    "    dist_posteriors[col].update({'Weibull': pd.read_csv(SAMPLES_PATH + col +'-samples-weibull_'+ strat + '.csv').agg(stat)})\n",
    "    dist_posteriors[col].update({'Exponential': pd.read_csv(SAMPLES_PATH + col +'-samples-exponential_'+ strat + '.csv').agg(stat)})\n",
    "    dist_posteriors[col].update({'Gen Lognormal': pd.read_csv(SAMPLES_PATH + col +'-samples-gln_'+ strat + '.csv').agg(stat)})\n",
    "    dist_posteriors[col].update({'Gamma 3p': pd.read_csv(SAMPLES_PATH + col +'-samples-gamma3p_'+ strat + '.csv').agg(stat)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame({})\n",
    "for dist in dist_posteriors:\n",
    "    best = df_best_models[df_best_models[dist] == 0].index[0]\n",
    "    df_temp = dist_posteriors[dist][best]\n",
    "    df_temp = df_temp.reset_index()\n",
    "    df_temp = df_temp.rename(columns = {'index':'stat'})\n",
    "    cols = ['t', 'best', 'stat'] + [col for col in df_temp.columns.tolist() if 'mu' in col]\n",
    "    df_temp['t'] = dist\n",
    "    df_temp['best'] = best\n",
    "    df_temp = df_temp[cols]\n",
    "    df_res = pd.concat([df_res, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_res.columns:\n",
    "    if 'mu' in col:\n",
    "        df_res[col] = np.exp(df_res[col]).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(RESULTS_PATH+'best_fit_summary.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d246ac5d3ecd9f71c37f1a40bf028688451278244d6d81eb19d5aa7eb10477f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
